{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS7T20gWaEkg"
      },
      "source": [
        "Projede trafik işaretleri veri kümesi ile CNN modelinin eğitilmesi\n",
        "\n",
        "Google Drive linki: https://drive.google.com/drive/u/1/folders/1Pe--TRsTpvR1c3mCOXV3SwmBxCT-yyim\n",
        "---\n",
        "\n",
        "*İçindekiler:*\n",
        "* [PyTorch](https://pytorch.org) hakkında\n",
        "* Trafik işaretlerini tanıması için sinir ağlarının eğitilmesi (MLP + CNN)\n",
        "* erişilebilir kıyaslama veri kümeleriyle(dataset) çalışma ([Traffic Sign Recognition Benchmark](https://benchmark.ini.rub.de/gtsrb_news.html))\n",
        "\n",
        "**Porgram çalıştırılırken GPU üzerinden çalıştırınız**\n",
        "\n",
        "Bu uygulamayı çalıştırmak için bir miktar Python ve numpy bilgisi gerekmektedir. Proram [Google Colab](https://colab.research.google.com/) üzerinde çalıştırılabilir veya tercihe göre Jüpiter not defteri kurup kullanabilirsiniz.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu0CrJ5N4ZuQ"
      },
      "source": [
        "## PyTorch Hakkında\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APZRY0-vEeC4"
      },
      "source": [
        "### Introduction to PyTorch\n",
        "\n",
        "[\"PyTorch Başlangıç\" eğitimi](https://pytorch.org/tutorials/beginner/basics/intro.html) bu 9 alt başlık üzerinden ilerler.\n",
        "\n",
        "*   Temeller\n",
        "*   Ufak bir başlangıç\n",
        "*   Tensörler (tensors)\n",
        "*   Veri Kümeleri (dataset) ve Veri Yükleyici (dataloader)\n",
        "*   Dönüşümler\n",
        "*   İnşa Modeli (Build Model)\n",
        "*   Autograd (PyTorch paketi)\n",
        "*   Optimizasyon\n",
        "*   Kaydetme ve Yükleme Modeli\n",
        "\n",
        "Proje için gerekli kodları Google Colab üzerinde inceleyebilir ve düzenleyebilirsiniz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH3vu3HiqaZS"
      },
      "source": [
        "## Hazırlıklar ve Eklemeler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJOOn6oO8X3C"
      },
      "source": [
        "Paket Yolu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPQaSW4f8aLt"
      },
      "outputs": [],
      "source": [
        "# Package Path (this needs to be adapted)\n",
        "packagePath = \"./\" # yerel\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  packagePath = \"/content/drive/MyDrive/a3-gtsrb/a3-gtsrb/templates\"   # Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFz0s31SxNyP"
      },
      "source": [
        "### Gerekli kütüphanelerin eklenmesi (Programın bu kodlarla başlaması gerekmektedir.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPcN62DgZ6Gg"
      },
      "outputs": [],
      "source": [
        "# os, glob, time, logging\n",
        "import os, glob, time, logging\n",
        "\n",
        "# NumPy\n",
        "import numpy as np\n",
        "\n",
        "# OpenCV\n",
        "import cv2\n",
        "\n",
        "# Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# yazıların resimlerin altında görünmesi için\n",
        "%matplotlib inline\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Google Colab'a özel paketler\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  # resim görünütleme için\n",
        "  from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANRNsyDPTm9x"
      },
      "source": [
        "\n",
        "### Gerekli olabilecek yardımcı fonksiyonlar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ5AIQr1TsHU"
      },
      "outputs": [],
      "source": [
        "def my_imshow(image, windowTitle=None, size=20, depth=3):\n",
        "  '''\n",
        "  Displays an image and differentiates between Google Colab and a local Python installation.\n",
        "\n",
        "  Args:\n",
        "    image: The image to be displayed\n",
        "\n",
        "  Returns:\n",
        "    -\n",
        "  '''\n",
        "\n",
        "  if 'google.colab' in str(get_ipython()):\n",
        "    print(windowTitle)\n",
        "    cv2_imshow(image)\n",
        "  else:\n",
        "    if (size):\n",
        "      (h, w) = image.shape[:2]\n",
        "      aspectRatio = float(h)/w\n",
        "      figsize=(size, size * aspectRatio)\n",
        "      plt.figure(figsize=figsize)\n",
        "\n",
        "    if (windowTitle):\n",
        "      plt.title(windowTitle)\n",
        "\n",
        "    if (depth == 1):\n",
        "      plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
        "    elif (depth == 3):\n",
        "      plt.imshow(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
        "    else:\n",
        "      plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybKcetvDlt-o"
      },
      "source": [
        "\n",
        "### Google Colab kullanımı:\n",
        "Mount the Google Drive associated with your Google account. You will have to click the authorization link and enter the obtained authorization code here in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88rhI7gsltLi"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRE7wONf8ez8"
      },
      "source": [
        "### PyTorch Eğiticisi ve Deneme Sınıfı\n",
        "\n",
        "Proje paketinin içinde, `torchHelpers.py` isimli Python kod dosyası ekledik. Bu dosya `Trainer` ve `Tester` isimli iki sınıf bulunduruyor. BUsınıflar sinir ağı eğitim döngülerini ve test kodunu içeriyor.\n",
        "Bu sınıfların kullanımı şu şekildedir: (Sınıfların kendi dökümantasyonu kullanımları için yeterli bir kaynaktır.):\n",
        "\n",
        "```\n",
        "# Train a neural network model\n",
        "# create a trainer\n",
        "trainer = Trainer(model, lossFunction, optimizer, device, logLevel=logging.INFO)\n",
        "# train the model\n",
        "trainer.train(trainLoader, valLoader, numberOfEpochs)\n",
        "\n",
        "# Test a neural network model\n",
        "# create a tester\n",
        "tester = Tester(model, device, logLevel=logging.INFO)\n",
        "# test the model\n",
        "tester.test(testLoader)\n",
        "```\n",
        "\n",
        "Hata mesajları ve doğrulamaalar `trainer.metrics` and `tester.metrics` dosyalarını eğittikten sonra çıkacaktır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzeMhjWs9v-5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(packagePath)\n",
        "\n",
        "from torchHelpers import Trainer, Tester\n",
        "\n",
        "help(Trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IxxAKTfxxiU"
      },
      "source": [
        "## PyTorch'ta Çok Katmanlı Algılayıcıları Kullanarak Trafik İşareti Sınıflandırması\n",
        "Bu aşamada çok katmanlı olarak nöral ağı PyTorch ile eğiteceğiz. [Örnek Trafik işareti Veri Kümesi](https://benchmark.ini.rub.de/gtsrb_news.html) kullanılacaktır. Önceden herhangi bir özellik dönüşümü olmayacaktır, girdi ögesi saf piksel verileridir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouyODhArcfUL"
      },
      "source": [
        "### Müsait cihazlardan en uygunu otomatik olarak seçilir (**kod kısım**)\n",
        "\n",
        "**Colab'da: Çalışma Zamanı(runtime) -> Çalışma zamanı türünü değiştir bölümünde \"GPU\"yu seçin**\n",
        "\n",
        "Örnek GPU cihazı:\n",
        "\n",
        "```\n",
        "Using device: cuda\n",
        "Tesla T4\n",
        "```\n",
        "\n",
        "\n",
        "İlerleyen aşamada verileri ve modeli bu cihaza kaydedeceğiz. PyTorch aygıt yönetimni otomatik olarak kendisi yapmaktadır (Cuda/ MPS vb için ayar yapmamıza gerek yok.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNBnGSlxrN4Q"
      },
      "outputs": [],
      "source": [
        "# Check the devices that we have available and prefer CUDA over MPS and CPU\n",
        "def autoselectDevice(verbose=1):\n",
        "\n",
        "    # default: CPU\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        # CUDA\n",
        "        device = torch.device('cuda')\n",
        "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "        # MPS (acceleration on Apple silicon M1 / M2 chips)\n",
        "        device = torch.device('mps')\n",
        "\n",
        "    if verbose:\n",
        "        print('Using device:', device)\n",
        "\n",
        "    # Additional Info when using cuda\n",
        "    if verbose and device.type == 'cuda':\n",
        "        print(torch.cuda.get_device_name(0))\n",
        "\n",
        "    return device\n",
        "\n",
        "# We transfer our model and data later to this device. If this is a GPU\n",
        "# PyTorch will take care of everything automatically.\n",
        "device = autoselectDevice(verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFzeGgygOeX8"
      },
      "source": [
        "### GTSRB Veri Kümesi ile başlangıç (**kod kısım**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXZ4tzXccZB9"
      },
      "outputs": [],
      "source": [
        "# GTSRB is available as standard dataset in PyTorch. Nice :)\n",
        "\n",
        "# Data is loaded and processed in batches of 'batchSize' images\n",
        "batchSize = 24\n",
        "\n",
        "# We can add a chain of transforms that is applied to the original data, e.g.\n",
        "#    resize all images to the same dimensions, e.g. 64x64 pixels\n",
        "#    convert (batch of) images to a tensor\n",
        "#    normalize pixel values (to 0-1)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((64, 64)), # resize to 64x64 pixels\n",
        "     transforms.ToTensor()        # convert to tensor. This will also normalize pixels to 0-1\n",
        "     ])\n",
        "\n",
        "# We construct several DataLoaders that take care of loading, storing, caching, pre-fetching the dataset.\n",
        "# We will have one DataLoader for training, validation and test data.\n",
        "\n",
        "# Training data\n",
        "trainSet = torchvision.datasets.GTSRB(root='./data', split='train',\n",
        "                                      download=True, transform=transform)\n",
        "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=batchSize,\n",
        "                                          shuffle=True, pin_memory=True, num_workers=2)\n",
        "numTrainSamples = len(trainSet)\n",
        "\n",
        "# Validation and test data\n",
        "# GTSRB only provides a single test set. To create a validation and test set,\n",
        "# we split the original GTSRB test set into two parts. The validation set is\n",
        "# used to tune performance during training. The test set is only used AFTER\n",
        "# training to evaluation the final performance.\n",
        "\n",
        "gtsrbTestSet = torchvision.datasets.GTSRB(root='./data', split='test',\n",
        "                                          download=True, transform=transform)\n",
        "\n",
        "# Split the original GTSRB test data into 75% used for validation and 25% used for testing\n",
        "# We do not need to shuffle the data, as we are processing every validation / test image exactly once\n",
        "length75Percent = int(0.75 * len(gtsrbTestSet))\n",
        "length25Percent = len(gtsrbTestSet) - length75Percent\n",
        "lengths = [length75Percent, length25Percent]\n",
        "valSet, testSet = torch.utils.data.random_split(gtsrbTestSet, lengths)\n",
        "valLoader = torch.utils.data.DataLoader(valSet, batch_size=batchSize,\n",
        "                                        shuffle=False, pin_memory=True, num_workers=2)\n",
        "numValSamples = len(valSet)\n",
        "\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=batchSize,\n",
        "                                         shuffle=False, pin_memory=True, num_workers=2)\n",
        "numTestSamples = len(testSet)\n",
        "\n",
        "# Available traffic sign classes in the dataset\n",
        "classes = [\n",
        "    \"Speed limit (20km/h)\",\n",
        "    \"Speed limit (30km/h)\",\n",
        "    \"Speed limit (50km/h)\",\n",
        "    \"Speed limit (60km/h)\",\n",
        "    \"Speed limit (70km/h)\",\n",
        "    \"Speed limit (80km/h)\",\n",
        "    \"End of speed limit (80km/h)\",\n",
        "    \"Speed limit (100km/h)\",\n",
        "    \"Speed limit (120km/h)\",\n",
        "    \"No passing\",\n",
        "    \"No passing for vehicles over 3.5 metric tons\",\n",
        "    \"Right-of-way at the next intersection\",\n",
        "    \"Priority road\",\n",
        "    \"Yield\",\n",
        "    \"Stop\",\n",
        "    \"No vehicles\",\n",
        "    \"Vehicles over 3.5 metric tons prohibited\",\n",
        "    \"No entry\",\n",
        "    \"General caution\",\n",
        "    \"Dangerous curve to the left\",\n",
        "    \"Dangerous curve to the right\",\n",
        "    \"Double curve\",\n",
        "    \"Bumpy road\",\n",
        "    \"Slippery road\",\n",
        "    \"Road narrows on the right\",\n",
        "    \"Road work\",\n",
        "    \"Traffic signals\",\n",
        "    \"Pedestrians\",\n",
        "    \"Children crossing\",\n",
        "    \"Bicycles crossing\",\n",
        "    \"Beware of ice/snow\",\n",
        "    \"Wild animals crossing\",\n",
        "    \"End of all speed and passing limits\",\n",
        "    \"Turn right ahead\",\n",
        "    \"Turn left ahead\",\n",
        "    \"Ahead only\",\n",
        "    \"Go straight or right\",\n",
        "    \"Go straight or left\",\n",
        "    \"Keep right\",\n",
        "    \"Keep left\",\n",
        "    \"Roundabout mandatory\",\n",
        "    \"End of no passing\",\n",
        "    \"End of no passing by vehicles over 3.5 metric tons\",\n",
        "]\n",
        "\n",
        "numClasses = len(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87UhB27vHF-2"
      },
      "source": [
        "### Veri kümesi sonuçlarını ekrana yazdırır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phTyA38CrN4R"
      },
      "outputs": [],
      "source": [
        "print(\"Dataset Statistics\")\n",
        "print(f\"  # of training samples:   {numTrainSamples}\")\n",
        "print(f\"  # of validation samples: {numValSamples}\")\n",
        "print(f\"  # of test samples:       {numTestSamples}\")\n",
        "print(f\"  # of different classes:  {numClasses}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfjD8gP3HOCC"
      },
      "source": [
        "### Sonucu görselleştirmek için eklenen kod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzSin5MirN4R"
      },
      "outputs": [],
      "source": [
        "# Visualize a random batch of data from the data set\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.cpu().numpy() # make sure image is in host memory\n",
        "\n",
        "    # normalize to 0-1 for visualization\n",
        "    minPixel = np.min(npimg)\n",
        "    maxPixel = np.max(npimg)\n",
        "    npimg = npimg - minPixel\n",
        "    npimg = npimg / (maxPixel-minPixel)\n",
        "\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "numRows = 8\n",
        "\n",
        "# get a single random batch of training images\n",
        "dataIter = iter(trainLoader)\n",
        "images, labels = next(dataIter)\n",
        "\n",
        "# print labels\n",
        "for i in range( batchSize // numRows ):\n",
        "    print('\\n'.join(f'Image {j:2d}: {classes[labels[j]]:5s}' for j in range((i*numRows), (i*numRows)+numRows)))\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images, nrow=numRows))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATTSTJH6P8ZX"
      },
      "source": [
        "### Neural Network Model Tanımlanması (**kod kısmı**)\n",
        "\n",
        "[Örnekteki](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) gibi standart bir \"ileri beslemeli (feed-forward)\" çok katmanlı algılayıcı tasarlamak istiyoruz. PyTorch terimleriyle, bu alt sınıflarını sınıflandıran ve [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) `__init__()` ve `forward()` içeren bir Python sınıfıdır. Not olarak [örnek](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)teki `nn.Sequential` kullanmak zorunda değiliz. Katmanları guruplandırmaya yarar ancak gerekli değildir. Her katman ayrı olarak değerlendirilebilir,([örnek](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-convolutional-neural-network)teki gibi).\n",
        "\n",
        "\n",
        "proje için aşağıdaki katmanlara ihtiyacımız var: (giriş ve çıkış değerler için)\n",
        "\n",
        "* Girdi değeri sadece piksel verilerden oluşacaktır, örnek olarak 12288 değeri (64x64x3 olarak tek düzleme işlenmiş görsel)\n",
        "* [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) her katmanda 512, 256, 128, 64 nöron bulunur.\n",
        "* Çıktı katmanı [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) `numClasses` nöronları ile katmanlanır, her sınıf için bir nöron.\n",
        "* Çıktı katmanındaki nöronlar hariç her nöron [`torch.nn.functional.leaky_relu`](https://pytorch.org/docs/stable/generated/torch.nn.functional.leaky_relu.html#torch.nn.functional.leaky_relu) aktivasyon fonksiyonuna sahiptir.\n",
        "* **Not olarak: Çıktı katmanında herhangi bir aktivasyon fonksiyonu olmaamlıdır. Hasar hesaplamasında otomatik olarak uygulanacaktır (CrossEntropy kaybı için softmax aktivasyonu).**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrPJ4BVfQFIV"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(12288, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 43)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 12288)\n",
        "\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = F.leaky_relu(self.fc3(x))\n",
        "        x = F.leaky_relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        output = x\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRk0xlhSV6FG"
      },
      "source": [
        "### `torchinfo` paketi kullanılarak oluşturduğumuz ağ modelinin bir özet görüntüsü ekrana yazdırılır. (**kod kısmı**)\n",
        "\n",
        "Örnek ekran alıntısı:\n",
        "```\n",
        "==========================================================================================\n",
        "Layer (type (var_name))                  Output Shape              Param #\n",
        "==========================================================================================\n",
        "Net (Net)                                [1, 43]                   --\n",
        "├─Linear (fc1)                           [1, 512]                  6,291,968\n",
        "├─Linear (fc2)                           [1, 256]                  131,328\n",
        "├─Linear (fc3)                           [1, 128]                  32,896\n",
        "├─Linear (fc4)                           [1, 64]                   8,256\n",
        "├─Linear (fc5)                           [1, 43]                   2,795\n",
        "==========================================================================================\n",
        "Total params: 6,467,243\n",
        "Trainable params: 6,467,243\n",
        "Non-trainable params: 0\n",
        "Total mult-adds (M): 6.47\n",
        "==========================================================================================\n",
        "Input size (MB): 0.05\n",
        "Forward/backward pass size (MB): 0.01\n",
        "Params size (MB): 25.87\n",
        "Estimated Total Size (MB): 25.93\n",
        "==========================================================================================\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19K2Ilh2rN4S"
      },
      "outputs": [],
      "source": [
        "# Instatiate our neural network\n",
        "network = Net()\n",
        "\n",
        "# Print a summary of the net\n",
        "%pip install torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(network, input_size=(1, 3, 64, 64), row_settings=[\"var_names\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5P7r_rHQ9hm"
      },
      "source": [
        "### Neural Network Eğitimi (kod içeriği)\n",
        "\n",
        "Modelimizi eğitmek için, bazı tanımlamalar yapmalıyız. Bunlar: loss function, optimizer and hyperparameters. Bunlar modelin eğitim sürecini kontrol eder.\n",
        "\n",
        "* [`torch.optim.AdamW`](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html?highlight=adamw#torch.optim.AdamW) 'lr=3e-4' olarak ayarlanan öğrenme oranı dışında varsayılan parametrelerle optimize edici olarak kullanılır.\n",
        "* [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) kayıp fonksiyonu olarak kullanılır. [Dökümantasyonda] (https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) belirtildiği gibi, kayıp hesaplaması sırasında softmax aktivasyonunun uygulanması gerekmektedir.\n",
        "* Modelin istendiği başarıya ulaşması için yaklaşık 15 deneme gerekmektedir.\n",
        "\n",
        "\n",
        "`Trainer` sınıfı ile algo-ılayıcı sinir ağını eğitin, sonra  `trainLoader` veri yükleyici olarak ekleyin (veriyi eğitmek için), `valLoader` veriyi doğrulamak için eklenir.\n",
        "\n",
        "Her deneme için süreç yaklaşık olarak 20 saniyedir(**GPU** üzerinden çalıştığı için kullanılan modele göre değişebilir). Eğitim (doğrulama) verileri 15 eğitimden sonra yaklaşık olarak %95 (%81) olamlıdır .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsVNpyKvRAUC"
      },
      "outputs": [],
      "source": [
        "##### YOUR CODE GOES HERE ######\n",
        "import torch.optim as optim\n",
        "network = Net()\n",
        "\n",
        "num_epochs = 15\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(network.parameters(), lr=3e-4)\n",
        "\n",
        "trainer = Trainer(network, criterion, optimizer, device, logLevel=logging.INFO)\n",
        "trainer.train(trainLoader, valLoader, num_epochs)\n",
        "################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrwavtq-Re_J"
      },
      "source": [
        "### Kayıp ve doğruluk davranışının görselleştirilmesi (**kod kısım**)\n",
        "\n",
        "`trainer.metrics`'te bulunan verileri kullanarak, aşağıdaki sonuçlara ulaştık:\n",
        "* Her denemede fonksiyon değeri olarak eğitim kaybı ve doğrulama kaybı.  \n",
        "* Her denemede fonksiyon değeri olarak eğitim doğruluğu ve doğrulama doğruluğu.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsa77qfRRrDv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Assuming trainer.metrics contains the necessary information\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(trainer.metrics['epochTrainLoss'], label='Training Loss')\n",
        "plt.plot(trainer.metrics['epochValLoss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(trainer.metrics['epochTrainAccuracy'], label='Training Accuracy')\n",
        "plt.plot(trainer.metrics['epochValAccuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzhYCKJYTiIb"
      },
      "source": [
        "### Örnek tahmin değerleri için modelin çeşitli görseller ile çalıştırılması (**kod kısım**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILGixiytTo2A"
      },
      "outputs": [],
      "source": [
        "# Run some batches of unseen test data through the network and visualize its predictions\n",
        "numBatches = 4\n",
        "numRows = 8\n",
        "\n",
        " # Iterator through the test DataLoader\n",
        "dataIter = iter(testLoader)\n",
        "\n",
        "# for each batch\n",
        "for batch in range(numBatches):\n",
        "\n",
        "    # get images and ground truth labels\n",
        "    images, labels = next(dataIter)\n",
        "\n",
        "    # push to the device used\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # forward pass of the batch of images\n",
        "    outputs = network(images)\n",
        "\n",
        "    # find the index of the class with the largest output\n",
        "    _, predictedLabels         = torch.max(outputs, 1)\n",
        "\n",
        "    # print labels and outputs\n",
        "    countCorrect = 0\n",
        "    for i in range( batchSize // numRows ):\n",
        "        for j in range((i*numRows), (i*numRows)+numRows):\n",
        "            print(f'Image {j:2d} - Label: {classes[labels[j]]:5s} | Prediction: {classes[predictedLabels[j]]:5s}')\n",
        "            if labels[j] == predictedLabels[j]:\n",
        "                countCorrect = countCorrect + 1\n",
        "\n",
        "    print(f\"\\n{(countCorrect / batchSize) * 100.0:.2f}% of test images correctly classified\")\n",
        "\n",
        "    # show images\n",
        "    imshow(torchvision.utils.make_grid(images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4W79bpYY1BO"
      },
      "source": [
        "### Önceden kullanılmamış veri kümelerinde modelin performansının değerlendirilmesi (**kod kısım**)\n",
        "\n",
        "Eklenen `Tester` sınıfını (aşağıda eklenmiştir) kullanarak modelin önceden kullanılmamış veri kümelerinde  `testLoader` ile test edilmesi. Eğitilmiş model yaklaşık olarak %80 oranında doğruluk payına sahiptir (+- 2% değitim sırasında gerçekleşebilecek rastgele durumlardan dolayı hata payı)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSjVLeXIrN4U"
      },
      "outputs": [],
      "source": [
        "###### YOUR CODE GOES HERE ######\n",
        "# Test the network on the final test set\n",
        "tester = Tester(network, device, logLevel=logging.INFO)\n",
        "tester.test(testLoader)\n",
        "#################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_uHg7EecLVh"
      },
      "source": [
        "## Convolutional Neural Networks kullanılarak Trafik İşareti Sınıflandırmanın  PyTorch ile gerçekleştirilmesi\n",
        "\n",
        "Bu kısımda CNN modelini pyTorch kullanarak [German Traffic Sign Recognition Benchmark](https://benchmark.ini.rub.de/gtsrb_news.html) veri kümesi ile eğitilecektir. Önceden herhangi bir özellik dönüşümü olmayacaktır, yani saf piksel değerleri girdi olacaktır.\n",
        "\n",
        "**Bunun için, aynı veri kümeleri, loss fonksiyonu, optimizer, hiperparametreler, 'Trainer' ve 'Test' sınıfı ile yukarıdaki işlemler tekrarlanabilir. Sadece farklı bir ağ modeli tanımlanmalı ve ağ parametrelerinin giriş olarak optimize edilmesi gerektirdiğinden optimize edicinin yeniden oluşturulması gerekir.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8zBN61-cr-2"
      },
      "source": [
        "### Convolutional Neural Network tanımlanması (**kod ksıım**)\n",
        "\n",
        "[Örnekteki](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) gibi bir CNN modeli tanımlamak için ağ sınıfımızın genel yapısı, çok katmanlı algılayanlar için öncekiyle aynıdır. Bununla birlikte, ek katmanlar (evrişim(convolutional) ve havuzlama(pooling) katmanları) kullanacağız.\n",
        "\n",
        "Girdi ve çıktı değerleri için aşağıdaki katmanları kullanmamız gerekiyor:\n",
        "\n",
        "* Giriş ham piksel değerleri, yani 64x64x3 (**çok katmanlı algılama için düzleştirilmez**) olacaktır.\n",
        "* 1 [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) 16 çıkış kanalı ile evrişimsel katman (farklı özellikler, 3x3 çekirdek (kernel) ve `padding='same'`\n",
        "* 1 [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) 16 çıkış kanalı ile evrişimsel katman (farklı özellikler, 3x3 çekirdek (kernel) ve `padding='same'`\n",
        "* 1 [`torch.nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d) 2x2 çekirdek ile havuzlama(pooling) katmanı\n",
        "* 1 [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) 32 çıkış kanalı ile evrişimsel katman (farklı özellikler, 3x3 çekirdek (kernel) ve `padding='same'`\n",
        "* 1 [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) 32 çıkış kanalı ile evrişimsel katman (farklı özellikler, 3x3 çekirdek (kernel) ve `padding='same'`\n",
        "* 1 [`torch.nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d) 2x2 çekirdek ile havuzlama(pooling) katmanı\n",
        "* 1 [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) 64 çıkış kanalı ile evrişimsel katman (farklı özellikler), 3x3 çekirdek (kernel) ve `padding='same'`\n",
        "* 1 [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) 64 çıkış kanalı ile evrişimsel katman (farklı özellikler), 3x3 çekirdek (kernel) ve `padding='same'`\n",
        "* 1 [`torch.nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d) 2x2 çekirdek ile havuzlama(pooling) katmanı\n",
        "* 1 [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) 64 nöron ile tam erişimli katman\n",
        "* Çıktı katmanı [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) `numClasses` nöronları ile tamamiyle bağlıdır, her sınıf için bir nöron.\n",
        "* Çıkış katmanındaki nöronlar ve havuz katmanları hariç tüm nöronlar [`torch.nn.functional.leaky_relu`](https://pytorch.org/docs/stable/generated/torch.nn.functional.leaky_relu.html#torch.nn.functional.leaky_relu) aktivasyon fonksiyonuna sahiptir.\n",
        "* **Önemli: Çıkış katmanının herhangi bir aktivasyon işlevi olmamalıdır. Kayıp hesaplaması sırasında otomatik olarak uygulanacaktır(CrossEntropy kaybı için softman aktivasyonu).**\n",
        "\n",
        "Model özeti için örnek ekran çıktısı:\n",
        "```\n",
        "==========================================================================================\n",
        "Layer (type (var_name))                  Output Shape              Param #\n",
        "==========================================================================================\n",
        "ConvNet (ConvNet)                        [1, 43]                   --\n",
        "├─Conv2d (conv1)                         [1, 16, 64, 64]           448\n",
        "├─Conv2d (conv2)                         [1, 16, 64, 64]           2,320\n",
        "├─MaxPool2d (pool)                       [1, 16, 32, 32]           --\n",
        "├─Conv2d (conv3)                         [1, 32, 32, 32]           4,640\n",
        "├─Conv2d (conv4)                         [1, 32, 32, 32]           9,248\n",
        "├─MaxPool2d (pool)                       [1, 32, 16, 16]           --\n",
        "├─Conv2d (conv5)                         [1, 64, 16, 16]           18,496\n",
        "├─Conv2d (conv6)                         [1, 64, 16, 16]           36,928\n",
        "├─MaxPool2d (pool)                       [1, 64, 8, 8]             --\n",
        "├─Linear (fc1)                           [1, 64]                   262,208\n",
        "├─Linear (fc2)                           [1, 43]                   2,795\n",
        "==========================================================================================\n",
        "Total params: 337,083\n",
        "Trainable params: 337,083\n",
        "Non-trainable params: 0\n",
        "Total mult-adds (M): 40.01\n",
        "==========================================================================================\n",
        "Input size (MB): 0.05\n",
        "Forward/backward pass size (MB): 1.84\n",
        "Params size (MB): 1.35\n",
        "Estimated Total Size (MB): 3.23\n",
        "==========================================================================================\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHXXZdufc4JY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchinfo import summary\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding='same')\n",
        "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, padding='same')\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding='same')\n",
        "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, padding='same')\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
        "        self.conv6 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 64)\n",
        "        self.fc2 = nn.Linear(64, 43)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.conv1(x))\n",
        "        x = F.leaky_relu(self.conv2(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.leaky_relu(self.conv3(x))\n",
        "        x = F.leaky_relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.leaky_relu(self.conv5(x))\n",
        "        x = F.leaky_relu(self.conv6(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfpnfmhyd_XP"
      },
      "outputs": [],
      "source": [
        "# Instantiate the CNN\n",
        "cnn = ConvNet()\n",
        "from torchinfo import summary\n",
        "summary(cnn, input_size=(1, 3, 64, 64), row_settings=[\"var_names\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Uycu6V2c61c"
      },
      "source": [
        "CNN modelini veri kümesinde eğittikten sonra önceki eğitimlerde kullanılmamış bir veri kümesi ile doğruluğunu test edin\n",
        "\n",
        "Modelin eğitimi her deneme için ortalama 20 saniye sürmelidir (**kullanılan GPU'ya göre süre değişebilir**). Yaklaşık olarak 15 deneme sonucunda modelin doğruluğu hatasız olmaya yaklaşmaktadır. Yeni ve daha önce eğitimde kullanılmamş (modelin eğitilmediği) bir veri kümesi için bu oran %90 civarındadır (15 eğitim sonrası)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ_pnGavdQgu"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Instantiate the CNN\n",
        "cnn = ConvNet()\n",
        "num_epochs = 15\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(cnn.parameters(), lr=3e-4)\n",
        "trainer = Trainer(cnn, criterion, optimizer, device, logLevel=logging.INFO)\n",
        "trainer.train(trainLoader, valLoader, num_epochs)\n",
        "\n",
        "# Test the network on the final test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z070U1iuTUYc"
      },
      "source": [
        "# ***Kaynakça***\n",
        "\n",
        "[1] https://kaanugurluoglu123.medium.com/nesne-tan%C4%B1ma-algoritmas%C4%B1-faster-r-cnn-nedir-1738f0cca8b7\n",
        "\n",
        "[2] https://ieeexplore.ieee.org/abstract/document/8756165\n",
        "\n",
        "[3] https://www.academia.edu/87657329/CNN_MODEL_FOR_TRAFFIC_SIGN_RECOGNITION?source=swp_share\n",
        "\n",
        "[4] https://www.youtube.com/watch?v=SWaYRyi0TTs&pp=ygUXY25uIG1vZGVsIGZvciB0cmFmZmljIHM%3D\n",
        "\n",
        "[5] https://www.youtube.com/watch?v=eS8sE1M9dks&pp=ygUXY25uIG1vZGVsIGZvciB0cmFmZmljIHM%3D\n",
        "\n",
        "[6] https://www.youtube.com/watch?v=4KEojbSJy4Y\n",
        "\n",
        "[7] https://www.youtube.com/watch?v=QzY57FaENXg&pp=ygUXY25uIG1vZGVsIGZvciB0cmFmZmljIHM%3D\n",
        "\n",
        "[8] https://www.diva-portal.org/smash/get/diva2:1575390/FULLTEXT02.pdf\n",
        "\n",
        "[9] https://pyimagesearch.com/2019/11/04/traffic-sign-classification-with-keras-and-deep-learning/\n",
        "\n",
        "[10] https://github.com/ItsCosmas/Traffic-Sign-Classification\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pytorch-m1",
      "language": "python",
      "name": "pytorch-m1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "be0721c968e9e259b6060574977180c78678bb42c4e1b679bdf73858ca605d14"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
